{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab:  Model Validation With Decision Trees\n",
    "\n",
    "Welcome to this evening's lab!  It's going to be a fun one.  For today's class, we're going to try and take a crack at model building in a wholistic way.  \n",
    "\n",
    "Specifically, we're going to try and do three different things:\n",
    "\n",
    " - Try out different versions of our data, and use our validation scores to see if something was an improvement or not\n",
    " - We're going to adjust model parameters to try and adjust our results to help curb overfitting\n",
    " - We're going to try and find model parameters that maximize our score for our dataset\n",
    " \n",
    "The idea is that we'll be able to do a mini-walkthrough to test what it's like to build and validate a model and try and improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Using the suggestions from the homework prompt given previously, try and add 3-4 different features ( columns ) to your data, and use your validation score to determine if they improved your results.  For now just stick with a tree that is 6 levels deep.\n",
    "\n",
    "This is meant to be open ended, and to allow you a chance to re-discover material from previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mcs275/dat-class-repo/master.csv', parse_dates = ['visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['id','visit_date']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_scores(df, estimator):\n",
    "    \n",
    "    df = df.drop('visit_date', axis = 1)\n",
    "    \n",
    "    # create training and validation set\n",
    "    train = df.groupby('id').apply(lambda x: x.iloc[:-15]).reset_index(drop = True)\n",
    "    val   = df.groupby('id').apply(lambda x: x.iloc[-15:]).reset_index(drop = True)\n",
    "    \n",
    "    # create a validation & test set\n",
    "    X_train, y_train = train.drop('visitors', axis = 1), train['visitors']\n",
    "    X_val, y_val     = val.drop('visitors', axis = 1), val['visitors']\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    # score on the test data\n",
    "    return estimator.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.groupby('id').apply(lambda x: x.iloc[:-15]).reset_index(drop = True)\n",
    "test  = df.groupby('id').apply(lambda x: x.iloc[-15:]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ce.TargetEncoder(), DecisionTreeRegressor(max_depth = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4795716486578089"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_scores(train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train['visit_date'].dt.month\n",
    "train['year'] = train['visit_date'].dt.year\n",
    "train['passage_of_time'] = (train['visit_date'] - train['visit_date'].min()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4794210840577293"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_scores(train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['month','year','passage_of_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4795716486578089"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_scores(train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the previous value and move it up one day (i.e. use yesterday's value)\n",
    "train['yesterday'] = train.groupby('id')['visitors'].shift()\n",
    "train['2dayago'] = train.groupby('id')['visitors'].shift(2)\n",
    "train['3dayago'] = train.groupby('id')['visitors'].shift(3)\n",
    "train['7dayago'] = train.groupby('id')['visitors'].shift(7)\n",
    "train['30dayago'] = train.groupby('id')['visitors'].shift(30)\n",
    "train = train.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912491788355623"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_scores(train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling7'] = train.groupby('id')['visitors'].rolling(7).mean().shift().values\n",
    "train['rolling30'] = train.groupby('id')['visitors'].rolling(30).mean().shift().values\n",
    "train['rolling90'] = train.groupby('id')['visitors'].rolling(90).mean().shift().values\n",
    "train = train.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5102922382918247"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_scores(train, pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Let's now try out different types of model parameters  \n",
    "\n",
    "The idea here is two-fold:  see if you can narrow the gap between in-sample and out-of-sample results (using training & validation sets), while simultaneously **not** decreasing your model scores (or at least not by very much).  The idea being that the closer these two are, the more reliable your results are likely to be.\n",
    "\n",
    "Some knobs you can turn:\n",
    " - `min_samples_leaf`: parameter in the category encoder that determines what cutoff point you can use for using the local vs. global average for the category.  (A decent rule of thumb is to try and have at least 10 samples on a leaf, but feel free to try different values)\n",
    " - `max_features`: what portion of columns to use at each split.  This parameter will randomly sample columns at each split, which reduces the chance that random patterns within them will have a disproportionately large impact on your model.  Should be a fraction between 0 and 1 or the number of columns you want to include.  \n",
    " - You can also try the following:  remove and sort of max_depth on your tree, and just use `min_samples_leaf` as a way to prune unnecessary splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Take the best version of your model & your data, and fit it on **all** of your training + validation data.  The idea is that now that we've found the best version of what we have to work with, we want to give it as much training samples as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Score your model on your test set.\n",
    "\n",
    "Note how your validation + test scores compared to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
